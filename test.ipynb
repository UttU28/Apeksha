{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because of a phenomenon called Rayleigh scattering, which is named after the British physicist Lord Rayleigh who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\n",
      "2. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths.\n",
      "3. This is because the smaller molecules are more effective at scattering the shorter wavelengths due to their smaller size.\n",
      "4. As a result, the blue light is scattered in all directions and reaches our eyes from all parts of the sky, making it appear blue.\n",
      "\n",
      "The reason we don't see the red light as much is that the longer wavelengths (like red) continue to travel in a more direct path to our eyes, which is why the sky often appears more blue during the daytime.\n",
      "\n",
      "However, there are some exceptions and variations:\n",
      "\n",
      "* During sunrise and sunset, the light has to travel through more of the atmosphere, scattering off more molecules and particles. This means that the shorter wavelengths (blue and violet) get scattered even more, making the sky appear redder.\n",
      "* At high altitudes or in areas with less atmospheric pollution, the blue color can be more pronounced because there are fewer molecules to scatter the light.\n",
      "* In some cases, the sky can take on hues of red, orange, or purple during severe thunderstorms or volcanic eruptions due to the presence of aerosols and particles in the atmosphere.\n",
      "\n",
      "So, that's why the sky appears blue!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished.\n",
      "Audio saved as prompt.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(filename=\"prompt.mp3\", duration=3, sample_rate=44100, channels=1, chunk=1024):\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=pyaudio.paInt16,\n",
    "                    channels=channels,\n",
    "                    rate=sample_rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(sample_rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    wf = wave.open(filename.replace('.mp3', '.wav'), 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(sample_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    print(f\"Audio saved as {filename.replace('.mp3', '.wav')}\")\n",
    "\n",
    "record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     result \u001b[38;5;241m=\u001b[39m pipe(audio_filepath)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./prompt.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(audio_filepath)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranscribe\u001b[39m(audio_filepath):\n\u001b[1;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m(audio_filepath)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "def transcribe(audio_filepath):\n",
    "    result = pipe(audio_filepath)\n",
    "    return result[\"text\"]\n",
    "\n",
    "transcribe(\"./prompt.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
